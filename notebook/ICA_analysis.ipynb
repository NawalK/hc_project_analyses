{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#f4665a>  ICA analysis </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: BMPD HC\n",
    "____________________________________________________\n",
    "\n",
    "**Description:** This notebook provides code for BOLD signal fMRI resting-state processing for the Biomarker for Parkinson's Disease (BMPD)data. \n",
    "We will used ICA analysis:\n",
    "CanICA is an ICA package for group-level analysis of fMRI data.  \n",
    "It brings a well-controlled group model, as well as a thresholding algorithm controlling for specificity and sensitivity with an explicit model of the signal.  \n",
    "The reference papers are: G. Varoquaux et al. \"A group model for stable multi-subject ICA on fMRI datasets\", NeuroImage Vol 51 (2010), p. 288-299\n",
    "G. Varoquaux et al. \"ICA-based sparse features recovery from fMRI datasets\", IEEE ISBI 2010, p. 1177\n",
    "\n",
    "\n",
    "**Toolbox required:** SpinalCordToolbox, FSL, nilearn toolbox, nipype, matlab\n",
    "\n",
    "**Inputs**:  \n",
    "This notebook required this the following prepross anatomical,fmri images \n",
    "\n",
    "**Ouputs**:\n",
    "See the output description at each step of the Notebook.\n",
    "\n",
    "____________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c> Imports </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/nilearn/__init__.py:69: FutureWarning: Python 3.6 support is deprecated and will be removed in release 0.10 of Nilearn. Consider switching to Python 3.8 or 3.9.\n",
      "  _python_deprecation_warnings()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "# Spinal cord Toolbox_________________________________________\n",
    "### Cerebro:\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/spinalcordtoolbox-5.0.0\")\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/spinalcordtoolbox-5.0.0/scripts\") #sys.path.insert(0, \"/cerebro/cerebro1/dataset/bmpd/derivatives/sc_preproc/code/sct/spinalcordtoolbox\")\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/code/\") #sys.path.insert(0, \"/cerebro/cerebro1/dataset/bmpd/derivatives/sc_preproc/code/sct/spinalcordtoolbox\")\n",
    "\n",
    "from spinalcordtoolbox.utils.sys import run_proc\n",
    "import glob, os\n",
    "from nilearn.maskers import NiftiMasker\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from canICA_analyses import ICA\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c>  I. Run the canICA analysis </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#00988c>  > Split dataset in subvolumes </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset config\n",
    "#config_spine_only_CL.json #../config/config_brsc_CL.json\n",
    "with open('../config/config_spine_only_CL.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "dataset=\"gva\" \n",
    "structures=[\"spinalcord\"] # [\"spinalcord\"] or [\"brain\",\"spinalcord\"] . double check the script for brainsc\n",
    "analysis=\"split_volumes\"\n",
    "if dataset ==\"gva\":\n",
    "    splits=[\"quart1\",\"quart2\",\"quart3\",\"quart4\"]\n",
    "    config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[5]\n",
    "elif dataset ==\"mtl\":\n",
    "    splits=[\"half1\",\"half2\"]\n",
    "    config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[9]\n",
    "\n",
    "for split in splits:\n",
    "    config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"]='/ICA/results_spine_only/'+dataset+'/spinalcord/' + analysis +\"/\" + split +\"/\"\n",
    "    \n",
    "    if not os.path.exists(config['main_dir']+ config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"]):\n",
    "        os.mkdir(config['main_dir'] + config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"])\n",
    "        \n",
    "    files_func={};func_allsbj={}\n",
    "    for structure in structures:\n",
    "        if len(structures) == 1:\n",
    "            ana=structure\n",
    "        else:\n",
    "            ana= \"brain_spinalcord\"\n",
    "        files_func[structure]=[];func_allsbj[structure]=[]\n",
    "        for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "            subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "            files_func[structure].append(glob.glob(config[\"data\"][dataset][\"inputs_ica\"][\"dir\"]+ '/sub-' + subject_name + '/'  + structure + '/*' + config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_spinalcord\"].split(\"s.nii.gz\")[0] + split + \"_s.nii.gz\")[0])\n",
    "\n",
    "    redo=True\n",
    "    \n",
    "    for k in config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]:\n",
    "        config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "        print(config[\"ica_ana\"][\"iter\"])\n",
    "\n",
    "        icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        #icas = ICA(files_func[structures[0]],files_func[structures[1]],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        if k==4:\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=1) # load or extract\n",
    "        if redo==True:\n",
    "            #all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "            components=icas.get_CCA(reducedata_all)\n",
    "            components_final,components_final_z=icas.get_ICA(components)\n",
    "            zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#00988c>  > Random subjects (n=) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tag_filename_ica'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b6bee071970c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msbj_nb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"list_subjects\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0msubject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"list_subjects\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msbj_nb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mfiles_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_ica\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/sub-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubject_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstructure\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_ica\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tag_filename_ica\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mredo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tag_filename_ica'"
     ]
    }
   ],
   "source": [
    "# Load the dataset config\n",
    "#config_spine_only_CL.json #../config/config_brsc_CL.json\n",
    "with open('../config/config_spine_only_CL.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "dataset=\"mtl\" \n",
    "structures=[\"spinalcord\"] # [\"spinalcord\"] or [\"brain\",\"spinalcord\"] . double check the script for brainsc\n",
    "n_subject=5\n",
    "\n",
    "\n",
    "split_file=pd.read_csv(config['main_dir']+ '/ICA/results_spine_only/'+dataset+'/spinalcord/split_'+str(n_subject)+'subjects/' + \"subperm.csv\",header=None)\n",
    "\n",
    "for iter in range(0,5):\n",
    "    config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"]='/ICA/results_spine_only/'+dataset+'/spinalcord/split_'+str(n_subject)+'subjects/n' + str(iter+1) + '/'\n",
    "    if not os.path.exists(config['main_dir']+ config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"]):\n",
    "        os.mkdir(config['main_dir'] + config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"])\n",
    "    config[\"list_subjects\"][dataset]\n",
    "\n",
    "    config[\"list_subjects\"][dataset]=split_file[iter].to_list()#config[\"list_subjects\"][dataset]=random.sample(config[\"list_subjects\"][dataset],k=n_subject)\n",
    "\n",
    "    files_func={};func_allsbj={}\n",
    "    for structure in structures:\n",
    "        if len(structures) == 1:\n",
    "            ana=structure\n",
    "        else:\n",
    "            ana= \"brain_spinalcord\"\n",
    "        files_func[structure]=[];func_allsbj[structure]=[]\n",
    "        for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "            subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "            files_func[structure].append(glob.glob(config[\"data\"][dataset][\"inputs_ica\"][\"dir\"]+ '/sub-' + subject_name + '/'  + structure + '/*' + config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_\" + ana] + '*')[0])\n",
    "  \n",
    "    redo=True\n",
    "    config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[5]\n",
    "    for k in config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]:\n",
    "        config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "        print(config[\"ica_ana\"][\"iter\"])\n",
    "\n",
    "        icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        #icas = ICA(files_func[structures[0]],files_func[structures[1]],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        if k==4:\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=1) # load or extract\n",
    "        if redo==True:\n",
    "            #all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "            components=icas.get_CCA(reducedata_all)\n",
    "            components_final,components_final_z=icas.get_ICA(components)\n",
    "            zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moco_HP_sc_inTemplate_s.nii.gz'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_\" + ana]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#00988c>  > Full dataset (classical analysis) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Analyse will be run on spinalcord structure\n",
      "Mask: /cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project//templates/PAM50/template/PAM50_cord_C5toC8.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-6f5711f825dd>\", line 34, in <module>\n",
      "    all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/code/canICA_analyses.py\", line 171, in get_data\n",
      "    for subject_name in self.config[\"list_subjects\"][self.dataset])\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/joblib/parallel.py\", line 1042, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/joblib/parallel.py\", line 921, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/_base.py\", line 427, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6f5711f825dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mall_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0micas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'extract'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acq_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load or extract, if NaN issues put both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mreducedata_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0micas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindiv_PCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_indiv_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# that step is not implanted to save individual maps for brain + sc yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/code/canICA_analyses.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, t_r, run, n_jobs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     data_sbj[structure]=Parallel(n_jobs=n_jobs)(delayed(self._extract_data)(subject_name,structure)\n\u001b[0;32m--> 171\u001b[0;31m                                            for subject_name in self.config[\"list_subjects\"][self.dataset])\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Load the dataset config\n",
    "#config_spine_only_CL.json #../config/config_brsc_CL.json\n",
    "with open('../config/config_spine_only_CL.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "dataset=\"gva\" \n",
    "structures=[\"spinalcord\"] # [\"spinalcord\"] or [\"brain\",\"spinalcord\"] . double check the script for brainsc\n",
    "\n",
    "\n",
    "config[\"list_subjects\"][dataset]\n",
    "\n",
    "files_func={};func_allsbj={}\n",
    "for structure in structures:\n",
    "    if len(structures) == 1:\n",
    "        ana=structure\n",
    "    else:\n",
    "        ana= \"brain_spinalcord\"\n",
    "    files_func[structure]=[];func_allsbj[structure]=[]\n",
    "    for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "        subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "        files_func[structure].append(glob.glob(config[\"data\"][dataset][\"inputs_ica\"][\"dir\"]+ '/sub-' + subject_name + '/'  + structure + '/*' + config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_\" + ana] + '*')[0])\n",
    "  \n",
    "redo=True\n",
    "config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[3]\n",
    "for k in config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]:\n",
    "    config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "    print(config[\"ica_ana\"][\"iter\"])\n",
    "\n",
    "    icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "    #icas = ICA(files_func[structures[0]],files_func[structures[1]],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "    if k==4:\n",
    "        all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=1) # load or extract\n",
    "    if redo==True:\n",
    "        #all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "        all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "        reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "        components=icas.get_CCA(reducedata_all)\n",
    "        components_final,components_final_z=icas.get_ICA(components)\n",
    "        zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c> II.  Run individual ICA </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "outputdir=[]\n",
    "config[\"ica_ana\"][\"iter\"]=500\n",
    "for sbj_nb in range(0,1):#len(config[\"list_subjects\"][dataset])):\n",
    "    subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "    print(subject_name)\n",
    "    config[\"ica_ana\"][\"n_comp\"]=9\n",
    "    \n",
    "    icas = ICA([files_func[structure][sbj_nb]],[''],structures,dataset,config,subject_name) \n",
    "    \n",
    "    # extract individual data\n",
    "    components=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "    components_final,components_final_z=icas.get_ICA(components.T,k=9) # components (n_voxels,n_volumes)\n",
    "    zcomponents4D_filename=icas.save_components(components_final,components_final_z,one_subject=subject_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Group ICA done <<\n"
     ]
    }
   ],
   "source": [
    "config[\"ica_ana\"][\"iter\"]=5\n",
    "\n",
    "components_final,components_final_z=icas.get_ICA(components.T,k=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project//ICA/results_spine_only/mtl/spinalcord////K_9/comp_indiv/CanICA_sub-P033_spinalcord_spinalcord_4D_K_9.nii.gz\n",
      ">> Components z-scored done <<\n"
     ]
    }
   ],
   "source": [
    "zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c> III.  Analyse to test iteration </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo=False\n",
    "for iter in [2000,5000]:\n",
    "    config[\"data\"][dataset]['ica'][\"spinalcord\"]['dir']='/ICA/results_spine_only/mtl/spinalcord/iterations_tests/' + str(iter) + \"/\"\n",
    "    config['ica_ana']['iter']=iter\n",
    "    config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[9]\n",
    "    print(\"Analyse is running for \" + dataset + \"and k= \" + str(config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]) + \" iter: \" + str(iter))\n",
    "    for k in config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]:\n",
    "        config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "        print(config[\"ica_ana\"][\"n_comp\"])\n",
    "        icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        \n",
    "        if k==4:\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=1) # load or extract\n",
    "        if redo==True:\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            all_data=icas.get_data(run='load',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "            components=icas.get_CCA(reducedata_all)\n",
    "            components_final,components_final_z=icas.get_ICA(components)\n",
    "            zcomponents4D_filename=icas.save_components(components_final,components_final_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c>  IV. Run spatial regression </font>\n",
    "To obtain matrices describing temporal dynamics for each component and subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform image into array\n",
    "load_img=True\n",
    "if load_img==True:\n",
    "    comp_raw_dir= config[\"main_dir\"] + config[\"data\"][dataset][\"ica\"][structure][\"dir\"] + '/' + '/K_' + str(config[\"ica_ana\"][\"n_comp\"]) + '/comp_raw/'\n",
    "    zcomponents4D_filename= glob.glob(comp_raw_dir + \"*4D*\")[0]\n",
    "    nifti_masker= NiftiMasker(mask_img=config[\"main_dir\"] + config[\"masks\"][dataset][structure]).fit() #Extract the data inside the mask and create a vector\n",
    "    components_final=nifti_masker.transform(zcomponents4D_filename).T # array for one subject, shape: n_volumes,n_voxels\n",
    "else:\n",
    "    components_final=components_final\n",
    "    \n",
    "output_dir=config[\"main_dir\"] + config[\"data\"][dataset][\"ica\"][structure][\"dir\"] + '/' + '/K_' + str(config[\"ica_ana\"][\"n_comp\"]) + '/comp_indiv_dynamic/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_dynamics_txt=[]\n",
    "temporal_dynamics=[]\n",
    "for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "    subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "    temporal_dynamics_txt.append(output_dir + \"sub-\" + subject_name + \"_K_\" + str(config[\"ica_ana\"][\"n_comp\"]) + \"_temporal_dynamic.txt\")\n",
    "    temporal_dynamics.append(icas.spatial_regression(components_final,all_data[sbj_nb],save=True,output_filename=temporal_dynamics_txt[sbj_nb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "dataset=\"mtl\"\n",
    "func=[]\n",
    "root_prep=\"/cerebro/cerebro1/dataset/\"\n",
    "for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "    subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "    if sbj_nb <12:\n",
    "        datas=\"bmpd/derivatives/spinalcord_processing/\"\n",
    "    else:\n",
    "        datas=\"stratals/derivatives/preprocessing/\"\n",
    "    func.append(glob.glob(root_prep + datas + \"sub-\" + subject_name + \"/func/5_Coregistration/spinalcord/*moco_mean_coreg_in_PAM50.nii.gz\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_4D=image.concat_imgs(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_4D=\"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_4D.nii.gz\"\n",
    "new_4D.to_filename(func_4D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fslmaths /cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_4D.nii.gz -Tmean /cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_mean.nii.gz # in /cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/notebook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, '')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_mean=\"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_mean.nii.gz\"\n",
    "run_proc(\"fslmaths {} -Tmean {}\".format(func_4D,func_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(config[\"list_subjects\"][dataset]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
