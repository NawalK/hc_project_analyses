{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#f4665a>  ICA analysis </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: BMPD HC\n",
    "____________________________________________________\n",
    "\n",
    "**Description:** This notebook provides code for BOLD signal fMRI resting-state processing for the Biomarker for Parkinson's Disease (BMPD)data. \n",
    "We will used ICA analysis:\n",
    "CanICA is an ICA package for group-level analysis of fMRI data.  \n",
    "It brings a well-controlled group model, as well as a thresholding algorithm controlling for specificity and sensitivity with an explicit model of the signal.  \n",
    "The reference papers are: G. Varoquaux et al. \"A group model for stable multi-subject ICA on fMRI datasets\", NeuroImage Vol 51 (2010), p. 288-299\n",
    "G. Varoquaux et al. \"ICA-based sparse features recovery from fMRI datasets\", IEEE ISBI 2010, p. 1177\n",
    "\n",
    "\n",
    "**Toolbox required:** SpinalCordToolbox, FSL, nilearn toolbox, nipype, matlab\n",
    "\n",
    "**Inputs**:  \n",
    "This notebook required this the following prepross anatomical,fmri images \n",
    "\n",
    "**Ouputs**:\n",
    "See the output description at each step of the Notebook.\n",
    "\n",
    "____________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c> Imports </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "# Spinal cord Toolbox_________________________________________\n",
    "### Cerebro:\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/spinalcordtoolbox-5.0.0\")\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/spinalcordtoolbox-5.0.0/scripts\") #sys.path.insert(0, \"/cerebro/cerebro1/dataset/bmpd/derivatives/sc_preproc/code/sct/spinalcordtoolbox\")\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/code/\") #sys.path.insert(0, \"/cerebro/cerebro1/dataset/bmpd/derivatives/sc_preproc/code/sct/spinalcordtoolbox\")\n",
    "\n",
    "from spinalcordtoolbox.utils.sys import run_proc\n",
    "import glob, os\n",
    "from nilearn.maskers import NiftiMasker\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from canICA_analyses import ICA\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c>  I. Run the canICA analysis </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#00988c>  > Split dataset in subvolumes </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset config\n",
    "#config_spine_only_CL.json #../config/config_brsc_CL.json\n",
    "with open('../config/config_spine_only_CL.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "dataset=\"gva\" \n",
    "structures=[\"spinalcord\"] # [\"spinalcord\"] or [\"brain\",\"spinalcord\"] . double check the script for brainsc\n",
    "analysis=\"split_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-P109', 'sub-P050', 'sub-P028', 'sub-P047', 'sub-P057']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#00988c>  > Random subjects (n=) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tag_filename_ica'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b6bee071970c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msbj_nb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"list_subjects\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0msubject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"list_subjects\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msbj_nb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mfiles_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_ica\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/sub-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubject_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstructure\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_ica\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tag_filename_ica\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mredo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tag_filename_ica'"
     ]
    }
   ],
   "source": [
    "# Load the dataset config\n",
    "#config_spine_only_CL.json #../config/config_brsc_CL.json\n",
    "with open('../config/config_spine_only_CL.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "dataset=\"mtl\" \n",
    "structures=[\"spinalcord\"] # [\"spinalcord\"] or [\"brain\",\"spinalcord\"] . double check the script for brainsc\n",
    "n_subject=5\n",
    "\n",
    "\n",
    "split_file=pd.read_csv(config['main_dir']+ '/ICA/results_spine_only/'+dataset+'/spinalcord/split_'+str(n_subject)+'subjects/' + \"subperm.csv\",header=None)\n",
    "\n",
    "for iter in range(0,5):\n",
    "    config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"]='/ICA/results_spine_only/'+dataset+'/spinalcord/split_'+str(n_subject)+'subjects/n' + str(iter+1) + '/'\n",
    "    if not os.path.exists(config['main_dir']+ config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"]):\n",
    "        os.mkdir(config['main_dir'] + config[\"data\"][dataset][\"ica\"][\"spinalcord\"][\"dir\"])\n",
    "    config[\"list_subjects\"][dataset]\n",
    "\n",
    "    config[\"list_subjects\"][dataset]=split_file[iter].to_list()#config[\"list_subjects\"][dataset]=random.sample(config[\"list_subjects\"][dataset],k=n_subject)\n",
    "\n",
    "    files_func={};func_allsbj={}\n",
    "    for structure in structures:\n",
    "        if len(structures) == 1:\n",
    "            ana=structure\n",
    "        else:\n",
    "            ana= \"brain_spinalcord\"\n",
    "        files_func[structure]=[];func_allsbj[structure]=[]\n",
    "        for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "            subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "            files_func[structure].append(glob.glob(config[\"data\"][dataset][\"inputs_ica\"][\"dir\"]+ '/sub-' + subject_name + '/'  + structure + '/*' + config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_\" + ana] + '*')[0])\n",
    "  \n",
    "    redo=True\n",
    "    config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[5]\n",
    "    for k in config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]:\n",
    "        config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "        print(config[\"ica_ana\"][\"iter\"])\n",
    "\n",
    "        icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        #icas = ICA(files_func[structures[0]],files_func[structures[1]],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        if k==4:\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=1) # load or extract\n",
    "        if redo==True:\n",
    "            #all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "            components=icas.get_CCA(reducedata_all)\n",
    "            components_final,components_final_z=icas.get_ICA(components)\n",
    "            zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moco_HP_sc_inTemplate_s.nii.gz'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_\" + ana]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#00988c>  > Full dataset (classical analysis) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset config\n",
    "#config_spine_only_CL.json #../config/config_brsc_CL.json\n",
    "with open('../config/config_spine_only_CL.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "dataset=\"gva\" \n",
    "structures=[\"spinalcord\"] # [\"spinalcord\"] or [\"brain\",\"spinalcord\"] . double check the script for brainsc\n",
    "\n",
    "\n",
    "config[\"list_subjects\"][dataset]\n",
    "\n",
    "files_func={};func_allsbj={}\n",
    "for structure in structures:\n",
    "    if len(structures) == 1:\n",
    "        ana=structure\n",
    "    else:\n",
    "        ana= \"brain_spinalcord\"\n",
    "    files_func[structure]=[];func_allsbj[structure]=[]\n",
    "    for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "        subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "        files_func[structure].append(glob.glob(config[\"data\"][dataset][\"inputs_ica\"][\"dir\"]+ '/sub-' + subject_name + '/'  + structure + '/*' + config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_\" + ana] + '*')[0])\n",
    "  \n",
    "redo=True\n",
    "config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[5]\n",
    "for k in config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]:\n",
    "    config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "    print(config[\"ica_ana\"][\"iter\"])\n",
    "\n",
    "    icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "    #icas = ICA(files_func[structures[0]],files_func[structures[1]],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "    if k==4:\n",
    "        all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=1) # load or extract\n",
    "     if redo==True:\n",
    "        #all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "        all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "        reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "        components=icas.get_CCA(reducedata_all)\n",
    "        components_final,components_final_z=icas.get_ICA(components)\n",
    "        zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c> II.  Run individual ICA </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "outputdir=[]\n",
    "config[\"ica_ana\"][\"iter\"]=500\n",
    "for sbj_nb in range(0,1):#len(config[\"list_subjects\"][dataset])):\n",
    "    subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "    print(subject_name)\n",
    "    config[\"ica_ana\"][\"n_comp\"]=9\n",
    "    \n",
    "    icas = ICA([files_func[structure][sbj_nb]],[''],structures,dataset,config,subject_name) \n",
    "    \n",
    "    # extract individual data\n",
    "    components=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "    components_final,components_final_z=icas.get_ICA(components.T,k=9) # components (n_voxels,n_volumes)\n",
    "    zcomponents4D_filename=icas.save_components(components_final,components_final_z,one_subject=subject_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/bmpd_python/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Group ICA done <<\n"
     ]
    }
   ],
   "source": [
    "config[\"ica_ana\"][\"iter\"]=5\n",
    "\n",
    "components_final,components_final_z=icas.get_ICA(components.T,k=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project//ICA/results_spine_only/mtl/spinalcord////K_9/comp_indiv/CanICA_sub-P033_spinalcord_spinalcord_4D_K_9.nii.gz\n",
      ">> Components z-scored done <<\n"
     ]
    }
   ],
   "source": [
    "zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c> III.  Analyse to test iteration </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo=False\n",
    "for iter in [2000,5000]:\n",
    "    config[\"data\"][dataset]['ica'][\"spinalcord\"]['dir']='/ICA/results_spine_only/mtl/spinalcord/iterations_tests/' + str(iter) + \"/\"\n",
    "    config['ica_ana']['iter']=iter\n",
    "    config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]=[9]\n",
    "    print(\"Analyse is running for \" + dataset + \"and k= \" + str(config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]) + \" iter: \" + str(iter))\n",
    "    for k in config[\"ica_ana\"][\"k_range\"][\"spinalcord\"]:\n",
    "        config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "        print(config[\"ica_ana\"][\"n_comp\"])\n",
    "        icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "        \n",
    "        if k==4:\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=1) # load or extract\n",
    "        if redo==True:\n",
    "            all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            all_data=icas.get_data(run='load',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "            reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "            components=icas.get_CCA(reducedata_all)\n",
    "            components_final,components_final_z=icas.get_ICA(components)\n",
    "            zcomponents4D_filename=icas.save_components(components_final,components_final_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c>  IV. Run spatial regression </font>\n",
    "To obtain matrices describing temporal dynamics for each component and subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform image into array\n",
    "load_img=True\n",
    "if load_img==True:\n",
    "    comp_raw_dir= config[\"main_dir\"] + config[\"data\"][dataset][\"ica\"][structure][\"dir\"] + '/' + '/K_' + str(config[\"ica_ana\"][\"n_comp\"]) + '/comp_raw/'\n",
    "    zcomponents4D_filename= glob.glob(comp_raw_dir + \"*4D*\")[0]\n",
    "    nifti_masker= NiftiMasker(mask_img=config[\"main_dir\"] + config[\"masks\"][dataset][structure]).fit() #Extract the data inside the mask and create a vector\n",
    "    components_final=nifti_masker.transform(zcomponents4D_filename).T # array for one subject, shape: n_volumes,n_voxels\n",
    "else:\n",
    "    components_final=components_final\n",
    "    \n",
    "output_dir=config[\"main_dir\"] + config[\"data\"][dataset][\"ica\"][structure][\"dir\"] + '/' + '/K_' + str(config[\"ica_ana\"][\"n_comp\"]) + '/comp_indiv_dynamic/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_dynamics_txt=[]\n",
    "temporal_dynamics=[]\n",
    "for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "    subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "    temporal_dynamics_txt.append(output_dir + \"sub-\" + subject_name + \"_K_\" + str(config[\"ica_ana\"][\"n_comp\"]) + \"_temporal_dynamic.txt\")\n",
    "    temporal_dynamics.append(icas.spatial_regression(components_final,all_data[sbj_nb],save=True,output_filename=temporal_dynamics_txt[sbj_nb]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "dataset=\"mtl\"\n",
    "func=[]\n",
    "root_prep=\"/cerebro/cerebro1/dataset/\"\n",
    "for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "    subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "    if sbj_nb <12:\n",
    "        datas=\"bmpd/derivatives/spinalcord_processing/\"\n",
    "    else:\n",
    "        datas=\"stratals/derivatives/preprocessing/\"\n",
    "    func.append(glob.glob(root_prep + datas + \"sub-\" + subject_name + \"/func/5_Coregistration/spinalcord/*moco_mean_coreg_in_PAM50.nii.gz\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_4D=image.concat_imgs(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_4D=\"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_4D.nii.gz\"\n",
    "new_4D.to_filename(func_4D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fslmaths /cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_4D.nii.gz -Tmean /cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_mean.nii.gz # in /cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/notebook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, '')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_mean=\"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/templates/PAM50/template/func_group_mean.nii.gz\"\n",
    "run_proc(\"fslmaths {} -Tmean {}\".format(func_4D,func_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(config[\"list_subjects\"][dataset]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
