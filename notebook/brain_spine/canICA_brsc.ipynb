{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#f4665a>  ICA analysis </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project: BMPD HC\n",
    "____________________________________________________\n",
    "\n",
    "**Description:** This notebook provides code for BOLD signal fMRI resting-state processing for the Biomarker for Parkinson's Disease (BMPD)data. \n",
    "We will used ICA analysis:\n",
    "CanICA is an ICA package for group-level analysis of fMRI data.  \n",
    "It brings a well-controlled group model, as well as a thresholding algorithm controlling for specificity and sensitivity with an explicit model of the signal.  \n",
    "The reference papers are: G. Varoquaux et al. \"A group model for stable multi-subject ICA on fMRI datasets\", NeuroImage Vol 51 (2010), p. 288-299\n",
    "G. Varoquaux et al. \"ICA-based sparse features recovery from fMRI datasets\", IEEE ISBI 2010, p. 1177\n",
    "\n",
    "\n",
    "**Toolbox required:** SpinalCordToolbox, FSL, nilearn toolbox, nipype, matlab\n",
    "\n",
    "**Inputs**:  \n",
    "This notebook required this the following prepross anatomical,fmri images \n",
    "\n",
    "**Ouputs**:\n",
    "See the output description at each step of the Notebook.\n",
    "\n",
    "____________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c> Imports </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "# Spinal cord Toolbox_________________________________________\n",
    "### Cerebro:\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/spinalcordtoolbox-5.0.0\")\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/thibault_test/code/toolbox/spinalcordtoolbox-5.0.0/scripts\") #sys.path.insert(0, \"/cerebro/cerebro1/dataset/bmpd/derivatives/sc_preproc/code/sct/spinalcordtoolbox\")\n",
    "sys.path.append(\"/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/code/\") #sys.path.insert(0, \"/cerebro/cerebro1/dataset/bmpd/derivatives/sc_preproc/code/sct/spinalcordtoolbox\")\n",
    "\n",
    "from spinalcordtoolbox.utils.sys import run_proc\n",
    "\n",
    "from canICA_analyses import ICA\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#00988c>  Run the ICA analysis </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset config\n",
    "#config_spine_only_CL.json #../config/config_brsc_CL.json\n",
    "with open('../../config/config_canICA_brsc.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "dataset=\"mtl\" \n",
    "structures=[\"brain\",\"spinalcord\"] # [\"spinalcord\"] or [\"brain\",\"spinalcord\"] . double check the script for brainsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files_func={};func_allsbj={}\n",
    "for structure in structures:\n",
    "    if len(structures) == 1:\n",
    "        ana=structure\n",
    "    else:\n",
    "        ana= \"brain_spinalcord\"\n",
    "    files_func[structure]=[];func_allsbj[structure]=[]\n",
    "    for sbj_nb in range(len(config[\"list_subjects\"][dataset])):\n",
    "        subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "        files_func[structure].append(glob.glob(config[\"data\"][dataset][\"inputs_ica\"][\"dir\"]+ '/sub-' + subject_name + '/'  + structure + '/*' + config[\"data\"][dataset][\"inputs_ica\"][structure][\"tag_filename_\" + ana] + '*')[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Analyse will be run on brain and spinalcord structures simultaneously\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project//hc_project_analyses/masks/brain_old_3mm/MNI_GM_3mm.nii\n",
      "/cerebro/cerebro1/dataset/bmpd/derivatives/HealthyControls_project/hc_project_analyses/masks/spinalcord/PAM50_C1C7_gmwm.nii.gz\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      "(265, 103503)\n",
      ">> Individual PCA done <<\n"
     ]
    }
   ],
   "source": [
    "config[\"ica_ana\"][\"k_range\"][ana]=[5]\n",
    "for k in config[\"ica_ana\"][\"k_range\"][ana]:\n",
    "    config[\"ica_ana\"][\"n_comp\"]=k # usefull if you want to test only on k\n",
    "    print(config[\"ica_ana\"][\"n_comp\"])\n",
    "    if ana == \"spinalcord\" or ana==\"brain\":\n",
    "        icas = ICA(files_func[structure],[''],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "    elif ana==\"brain_spinalcord\":\n",
    "        icas = ICA(files_func[structures[0]],files_func[structures[1]],structures,dataset,config) # \"brain_spinalcord\" or \"brain\" or \"spinalcord\"\n",
    "    \n",
    "    all_data=icas.get_data(run='extract',t_r=config[\"acq_params\"][dataset][\"TR\"],n_jobs=8) # load or extract, if NaN issues put both\n",
    "    reducedata_all=icas.indiv_PCA(all_data,save_indiv_img=True) # that step is not implanted to save individual maps for brain + sc yet\n",
    "    \n",
    "    components=icas.get_CCA(reducedata_all)\n",
    "    components_final,components_final_z=icas.get_ICA(components)\n",
    "    zcomponents4D_filename=icas.save_components(components_final,components_final_z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Components z-scored done <<\n"
     ]
    }
   ],
   "source": [
    "zcomponents4D_filename=icas.save_components(components_final,components_final_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_z={}\n",
    "analyse_dir=config[\"main_dir\"] + config[\"data\"][dataset][\"ica\"][structures[0]+'_'+structures[1]][\"dir\"]+'/' + '/' + '/K_' + str(config[\"ica_ana\"][\"n_comp\"])\n",
    "\n",
    "for structure in structures:\n",
    "    components_z[structure]=np.zeros(shape=(components_final[structure].shape[0],components_final[structure].shape[1]),dtype='float')\n",
    "    nifti_masker[structure]= NiftiMasker(mask_img=config[\"main_dir\"] + config[\"masks\"][dataset][structure], standardize=False,smoothing_fwhm=None).fit() #Extract the data inside the mask and create a vector\n",
    "    for i in range(0,len(components_final[structure].T)):\n",
    "        med  = np.median(components_final[structure])\n",
    "        components_z[structure][:,i] = (components_final[structure][:,i]-med)/np.sqrt((np.sum((components_final[structure][:,i]-med)**2))/len(components_final[structure][:,i]))   # normalization \n",
    "        zcomponents_img = nifti_masker[structure].inverse_transform(components_z[structure].T) #check the component\n",
    "        \n",
    "        zcomponents4D_filename=analyse_dir  + '/comp_zscored/CanICA_' + str(len(config[\"list_subjects\"][dataset])) + 'sbj_'+ structures[0] +'_'+ structure + '_K_'+ str(config[\"ica_ana\"][\"n_comp\"]) + '_4D_z.nii.gz'\n",
    "        zcomponents_img.to_filename(zcomponents4D_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "20*31\n",
    "from nilearn.maskers import NiftiMasker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50572)\n",
      "(20, 50572)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'spinalcord'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reducedata_all[j-n_comp_pca:j,0:n_voxels[structures[0]]].shape)\n",
    "print(reducedata_all[j-n_comp_pca:j,n_voxels[structures[1]]:].shape)\n",
    "#n_voxels[structures[1]].shape\n",
    "structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50572\n",
      "52931\n"
     ]
    }
   ],
   "source": [
    "nifti_masker={};n_voxels={};components_final={}\n",
    "components_img={}\n",
    "n_comp_pca=20\n",
    "for structure in structures:\n",
    "    nifti_masker[structure]= NiftiMasker(mask_img=config[\"main_dir\"] + config[\"masks\"][dataset][structure], standardize=False,smoothing_fwhm=None).fit() #Extract the data inside the mask and create a vector\n",
    "    n_voxels[structure]= nifti_masker[structure].fit_transform(config[\"main_dir\"] + config[\"masks\"][dataset][structure]).shape[1] # number of voxels in the structure\n",
    "print(n_voxels[structures[0]])\n",
    "print(n_voxels[structures[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_dir=config[\"main_dir\"] + config[\"data\"][dataset][\"ica\"][structures[0]+'_'+structures[1]][\"dir\"]+'/' + '/' + '/K_' + str(config[\"ica_ana\"][\"n_comp\"])\n",
    "nifti_masker={};n_voxels={};components_final={}\n",
    "components_img={}\n",
    "n_comp_pca=20\n",
    "for structure in structures:\n",
    "    nifti_masker[structure]= NiftiMasker(mask_img=config[\"main_dir\"] + config[\"masks\"][dataset][structure], standardize=False,smoothing_fwhm=None).fit() #Extract the data inside the mask and create a vector\n",
    "    n_voxels[structure]= nifti_masker[structure].fit_transform(config[\"main_dir\"] + config[\"masks\"][dataset][structure]).shape[1] # number of voxels in the structure\n",
    "       \n",
    "    j=0\n",
    "    for sbj_nb in range(0,len(config[\"list_subjects\"][dataset])):\n",
    "        subject_name=config[\"list_subjects\"][dataset][sbj_nb]\n",
    "        for i in range(j,j+n_comp_pca):\n",
    "            j=i\n",
    "            j=+i+1\n",
    "        \n",
    "        if structure==structures[0]:\n",
    "            components_img[structures[0]] = nifti_masker[structures[0]].inverse_transform(reducedata_all[j-n_comp_pca:j,0:n_voxels[structures[0]]]) # transform the components in nifti\n",
    "            components_img[structures[0]].to_filename(analyse_dir + '/pca_indiv/sub-' + subject_name +'_'+structures[0]+'_comp_PCA.nii.gz') #save the n principal components for each subject\n",
    "  \n",
    "        else:\n",
    "            components_img[structures[1]] = nifti_masker[structures[1]].inverse_transform(reducedata_all[j-n_comp_pca:j,n_voxels[structures[0]]:]) # transform the components in nifti\n",
    "            components_img[structures[1]].to_filename(analyse_dir + '/pca_indiv/sub-' + subject_name +'_'+structures[1]+'_comp_PCA.nii.gz') #save the n principal components for each subject\n",
    "  \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-69a9349fd5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reducedata_all[j-n_comp_pca:j,0:n_voxels[structure[0]]].shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_voxels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'b'"
     ]
    }
   ],
   "source": [
    "#reducedata_all[j-n_comp_pca:j,0:n_voxels[structure[0]]].shape\n",
    "n_voxels[structure[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save PCA\n",
    "\n",
    "# For brain and spinal cord analyses split the component in two voxel matrices to be transform in two separates images in the next step\n",
    "if len(structures_ana) == 2:\n",
    "    n_voxels={};nifti_masker={}\n",
    "    for structure in structures:\n",
    "        nifti_masker[structure]= NiftiMasker(mask_img=config[\"main_dir\"] + config[\"masks\"][dataset][structure], standardize=False,smoothing_fwhm=None).fit() #Extract the data inside the mask and create a vector\n",
    "        n_voxels[structure]= nifti_masker[structure].fit_transform(config[\"main_dir\"] + config[\"masks\"][self.dataset][structure]).shape[1] # number of voxels in the structure\n",
    "        components_final[structure]=np.empty(shape=(n_voxels[structure],config[\"ica_ana\"][\"n_comp\"]),dtype='float') # matrix of brain voxels \n",
    "        components_final_z[structure]=np.empty(shape=(n_voxels[structure],config[\"ica_ana\"][\"n_comp\"]),dtype='float') # matrix of brain voxels \n",
    "            \n",
    "        for voxel in range(0,n_voxels[structures[0]]):\n",
    "            components_final[structures[0]][voxel,:]=components_[voxel,:]\n",
    "            #components_final_z[self.structures[0]][voxel,:]=components_z[voxel,:]\n",
    "        for voxel in range(n_voxels[structures[0]],n_voxels[structures[0]]+n_voxels[structures[1]]):\n",
    "            components_final[structures[1]][voxel-n_voxels[structures[0]],:]=components_[voxel,:]\n",
    "            #components_final_z[self.structures[1]][voxel-n_voxels[self.structures[0]],:]=components_z[voxel,:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
